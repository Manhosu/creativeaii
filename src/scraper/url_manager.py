"""
URL Manager
Gerencia URLs de categorias e controle de produtos processados
"""

import os
import json
import sqlite3
from typing import List, Dict, Set, Optional, Any
from datetime import datetime, timedelta
from loguru import logger
import hashlib
from .category_discovery import CategoryDiscovery
from ..config.active_categories_manager import ActiveCategoriesManager

class URLManager:
    """Gerenciador de URLs e cache de produtos processados"""
    
    def __init__(self, db_path: str = "logs/products_cache.db"):
        """
        Inicializa o gerenciador de URLs
        
        Args:
            db_path: Caminho para banco de dados SQLite
        """
        self.db_path = db_path
        self.category_urls = []
        self.processed_products = set()
        self.discovered_categories = []  # Cache de categorias descobertas
        
        # Inicializar gerenciador de categorias ativas
        self.active_categories_manager = ActiveCategoriesManager()
        
        # Inicializar banco de dados
        self._init_database()
        
        # Carregar URLs das configurias ativas apenas
        self._load_category_urls()
        
        # Carregar produtos j√° processados
        self._load_processed_products()
        
        # Inicializar descobridor de categorias
        self.category_discovery = CategoryDiscovery()
        
        logger.info(f"üîó URL Manager inicializado com {len(self.category_urls)} URLs")
    
    def _init_database(self):
        """Inicializa banco de dados SQLite"""
        try:
            # Criar diret√≥rio se n√£o existir
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Tabela de produtos processados
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS processed_products (
                        id TEXT PRIMARY KEY,
                        nome TEXT NOT NULL,
                        url TEXT,
                        categoria_url TEXT,
                        data_processed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        hash_content TEXT,
                        status TEXT DEFAULT 'processed'
                    )
                ''')
                
                # Tabela de estat√≠sticas de scraping
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS scraping_stats (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        categoria_url TEXT NOT NULL,
                        total_produtos INTEGER,
                        novos_produtos INTEGER,
                        data_scraping TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        tempo_execucao REAL,
                        status TEXT
                    )
                ''')
                
                # √çndices para performance
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_product_id ON processed_products(id)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_categoria_url ON processed_products(categoria_url)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_data_processed ON processed_products(data_processed)')
                
                conn.commit()
                
            logger.info("‚úÖ Banco de dados inicializado com sucesso")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar banco de dados: {e}")
    
    def _load_category_urls(self):
        """Carrega URLs apenas das categorias ativas"""
        try:
            # Carregar URLs das categorias ativas
            active_urls = self.active_categories_manager.get_active_urls()
            
            if active_urls:
                self.category_urls = active_urls
                active_categories = self.active_categories_manager.get_active_categories()
                logger.info(f"üìã {len(self.category_urls)} URLs carregadas das categorias ativas:")
                for category in active_categories:
                    logger.info(f"  ‚úÖ {category['category_name']}: {category['category_url']}")
                return
            else:
                logger.warning("‚ö†Ô∏è Nenhuma categoria ativa encontrada!")
                    
                # Fallback: carregar URLs do ConfigManager (compatibilidade)
                try:
                    from ..config.config_manager import ConfigManager
                    config_manager = ConfigManager()
                    monitored_urls = config_manager.get_monitored_urls(active_only=True)
                    
                    if monitored_urls:
                        self.category_urls = [url['url'] for url in monitored_urls]
                        logger.info(f"üîß Fallback: {len(self.category_urls)} URLs do ConfigManager")
                        
                except Exception as config_error:
                    logger.warning(f"‚ö†Ô∏è Erro no fallback ConfigManager: {config_error}")
            
                # URLs padr√£o se nada funcionar
            self.category_urls = [
                "https://www.creativecopias.com.br/impressoras",
                "https://www.creativecopias.com.br/cartuchos-de-toner"
            ]
            
            logger.info(f"üîß Usando URLs padr√£o: {len(self.category_urls)} URLs")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar URLs das categorias ativas: {e}")
            self.category_urls = []
    
    def _load_processed_products(self):
        """Carrega lista de produtos j√° processados"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('SELECT id FROM processed_products')
                results = cursor.fetchall()
                
                self.processed_products = set(row[0] for row in results)
                
            logger.info(f"üì¶ {len(self.processed_products)} produtos j√° processados carregados")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar produtos processados: {e}")
            self.processed_products = set()
    
    def get_category_urls(self) -> List[str]:
        """
        Retorna lista de URLs de categorias
        
        Returns:
            Lista de URLs
        """
        return self.category_urls.copy()
    
    def refresh_category_urls(self):
        """Recarrega URLs das configura√ß√µes"""
        logger.info("üîÑ Recarregando URLs das configura√ß√µes...")
        old_count = len(self.category_urls)
        self._load_category_urls()
        new_count = len(self.category_urls)
        logger.info(f"üìä URLs atualizadas: {old_count} ‚Üí {new_count}")
    
    def add_category_url(self, url: str) -> bool:
        """
        Adiciona nova URL de categoria
        
        Args:
            url: URL para adicionar
            
        Returns:
            True se adicionada com sucesso
        """
        try:
            if url not in self.category_urls:
                self.category_urls.append(url)
                logger.info(f"‚ûï URL adicionada: {url}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è URL j√° existe: {url}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erro ao adicionar URL: {e}")
            return False
    
    def remove_category_url(self, url: str) -> bool:
        """
        Remove URL de categoria
        
        Args:
            url: URL para remover
            
        Returns:
            True se removida com sucesso
        """
        try:
            if url in self.category_urls:
                self.category_urls.remove(url)
                logger.info(f"‚ûñ URL removida: {url}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è URL n√£o encontrada: {url}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erro ao remover URL: {e}")
            return False
    
    def is_product_processed(self, product_id: str) -> bool:
        """
        Verifica se produto j√° foi processado
        
        Args:
            product_id: ID do produto
            
        Returns:
            True se j√° foi processado
        """
        return product_id in self.processed_products
    
    def mark_product_as_processed(self, product: Dict[str, Any]) -> bool:
        """
        Marca produto como processado
        
        Args:
            product: Dados do produto
            
        Returns:
            True se marcado com sucesso
        """
        try:
            product_id = product.get('id')
            if not product_id:
                logger.error("‚ùå Produto sem ID n√£o pode ser marcado como processado")
                return False
            
            # Gerar hash do conte√∫do para detectar mudan√ßas
            content_hash = self._generate_content_hash(product)
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT OR REPLACE INTO processed_products 
                    (id, nome, url, categoria_url, hash_content, status)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    product_id,
                    product.get('nome', ''),
                    product.get('url', ''),
                    product.get('categoria_url', ''),
                    content_hash,
                    'processed'
                ))
                
                conn.commit()
            
            # Adicionar ao cache em mem√≥ria
            self.processed_products.add(product_id)
            
            logger.debug(f"‚úÖ Produto marcado como processado: {product.get('nome', 'N/A')}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao marcar produto como processado: {e}")
            return False
    
    def mark_products_as_processed(self, products: List[Dict[str, Any]]) -> int:
        """
        Marca m√∫ltiplos produtos como processados
        
        Args:
            products: Lista de produtos
            
        Returns:
            N√∫mero de produtos marcados com sucesso
        """
        success_count = 0
        
        for product in products:
            if self.mark_product_as_processed(product):
                success_count += 1
        
        logger.info(f"‚úÖ {success_count}/{len(products)} produtos marcados como processados")
        return success_count
    
    def filter_new_products(self, products: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtra apenas produtos novos (n√£o processados)
        
        Args:
            products: Lista de produtos
            
        Returns:
            Lista de produtos novos
        """
        new_products = []
        
        for product in products:
            product_id = product.get('id')
            if product_id and not self.is_product_processed(product_id):
                new_products.append(product)
            elif product_id:
                # Verificar se o conte√∫do mudou
                if self._has_product_changed(product):
                    new_products.append(product)
                    logger.debug(f"üîÑ Produto atualizado detectado: {product.get('nome', 'N/A')}")
        
        logger.info(f"üÜï {len(new_products)}/{len(products)} produtos novos encontrados")
        return new_products
    
    def _has_product_changed(self, product: Dict[str, Any]) -> bool:
        """
        Verifica se produto foi alterado desde √∫ltimo processamento
        
        Args:
            product: Dados do produto
            
        Returns:
            True se foi alterado
        """
        try:
            product_id = product.get('id')
            if not product_id:
                return True
            
            # Buscar hash anterior
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('SELECT hash_content FROM processed_products WHERE id = ?', (product_id,))
                result = cursor.fetchone()
                
                if not result:
                    return True  # Produto novo
                
                old_hash = result[0]
                new_hash = self._generate_content_hash(product)
                
                return old_hash != new_hash
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar mudan√ßas no produto: {e}")
            return True  # Em caso de erro, considerar como alterado
    
    def _generate_content_hash(self, product: Dict[str, Any]) -> str:
        """
        Gera hash do conte√∫do do produto para detectar mudan√ßas
        
        Args:
            product: Dados do produto
            
        Returns:
            Hash MD5 do conte√∫do
        """
        # Campos relevantes para detectar mudan√ßas
        relevant_fields = ['nome', 'preco', 'descricao', 'disponivel']
        content_string = ""
        
        for field in relevant_fields:
            value = product.get(field, '')
            if value:
                content_string += str(value)
        
        return hashlib.md5(content_string.encode()).hexdigest()
    
    def record_scraping_stats(self, categoria_url: str, total_produtos: int, 
                            novos_produtos: int, tempo_execucao: float, 
                            status: str = "success") -> bool:
        """
        Registra estat√≠sticas do scraping
        
        Args:
            categoria_url: URL da categoria processada
            total_produtos: Total de produtos encontrados
            novos_produtos: Produtos novos processados
            tempo_execucao: Tempo em segundos
            status: Status da opera√ß√£o
            
        Returns:
            True se registrado com sucesso
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO scraping_stats 
                    (categoria_url, total_produtos, novos_produtos, tempo_execucao, status)
                    VALUES (?, ?, ?, ?, ?)
                ''', (categoria_url, total_produtos, novos_produtos, tempo_execucao, status))
                
                conn.commit()
            
            logger.info(f"üìä Estat√≠sticas registradas: {novos_produtos}/{total_produtos} produtos novos")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao registrar estat√≠sticas: {e}")
            return False
    
    def get_scraping_stats(self, days: int = 7) -> List[Dict[str, Any]]:
        """
        Recupera estat√≠sticas de scraping dos √∫ltimos dias
        
        Args:
            days: N√∫mero de dias para buscar
            
        Returns:
            Lista de estat√≠sticas
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                date_limit = datetime.now() - timedelta(days=days)
                
                cursor.execute('''
                    SELECT categoria_url, total_produtos, novos_produtos, 
                           data_scraping, tempo_execucao, status
                    FROM scraping_stats 
                    WHERE data_scraping >= ?
                    ORDER BY data_scraping DESC
                ''', (date_limit,))
                
                results = cursor.fetchall()
                
                stats = []
                for row in results:
                    stats.append({
                        'categoria_url': row[0],
                        'total_produtos': row[1],
                        'novos_produtos': row[2],
                        'data_scraping': row[3],
                        'tempo_execucao': row[4],
                        'status': row[5]
                    })
                
                return stats
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao recuperar estat√≠sticas: {e}")
            return []
    
    def cleanup_old_records(self, days: int = 30) -> int:
        """
        Remove registros antigos do banco
        
        Args:
            days: Manter apenas registros dos √∫ltimos X dias
            
        Returns:
            N√∫mero de registros removidos
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                date_limit = datetime.now() - timedelta(days=days)
                
                # Limpar estat√≠sticas antigas
                cursor.execute('DELETE FROM scraping_stats WHERE data_scraping < ?', (date_limit,))
                stats_removed = cursor.rowcount
                
                # Limpar produtos muito antigos (manter √∫ltimos 90 dias)
                old_date_limit = datetime.now() - timedelta(days=90)
                cursor.execute('DELETE FROM processed_products WHERE data_processed < ?', (old_date_limit,))
                products_removed = cursor.rowcount
                
                conn.commit()
                
                # Recarregar produtos processados
                self._load_processed_products()
                
                total_removed = stats_removed + products_removed
                logger.info(f"üßπ Limpeza conclu√≠da: {total_removed} registros removidos")
                
                return total_removed
                
        except Exception as e:
            logger.error(f"‚ùå Erro na limpeza de registros: {e}")
            return 0
    
    def export_processed_products(self, filename: str = None) -> str:
        """
        Exporta lista de produtos processados
        
        Args:
            filename: Nome do arquivo (opcional)
            
        Returns:
            Caminho do arquivo criado
        """
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"logs/processed_products_{timestamp}.json"
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT id, nome, url, categoria_url, data_processed, status
                    FROM processed_products 
                    ORDER BY data_processed DESC
                ''')
                
                results = cursor.fetchall()
                
                products = []
                for row in results:
                    products.append({
                        'id': row[0],
                        'nome': row[1],
                        'url': row[2],
                        'categoria_url': row[3],
                        'data_processed': row[4],
                        'status': row[5]
                    })
                
                export_data = {
                    'total_produtos': len(products),
                    'data_export': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'produtos': products
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"üíæ Produtos processados exportados para: {filename}")
                return filename
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao exportar produtos processados: {e}")
            return ""
    
    def get_summary(self) -> Dict[str, Any]:
        """
        Retorna resumo do gerenciador de URLs
        
        Returns:
            Dicion√°rio com estat√≠sticas
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Contar produtos reais dos arquivos JSON
                import glob
                import json
                import os
                
                total_processed = 0
                categories = {}
                
                # Buscar todos os arquivos JSON de produtos
                json_files = glob.glob("logs/products_*.json")
                
                for json_file in json_files:
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            
                            # Extrair categoria do nome do arquivo
                            filename = os.path.basename(json_file)
                            categoria_key = filename.replace('products_', '').split('_')[0]
                            
                            # Contar produtos
                            if isinstance(data, list):
                                count = len(data)
                                total_processed += count
                                categories[categoria_key] = categories.get(categoria_key, 0) + count
                            elif isinstance(data, dict) and 'produtos' in data:
                                count = len(data['produtos'])
                                total_processed += count
                                categories[categoria_key] = categories.get(categoria_key, 0) + count
                    except Exception as e:
                        logger.warning(f"Erro ao ler arquivo {json_file}: {e}")
                        continue
                
                # √öltimas estat√≠sticas (manter do banco de dados)
                cursor.execute('''
                    SELECT SUM(total_produtos), SUM(novos_produtos), AVG(tempo_execucao)
                    FROM scraping_stats 
                    WHERE data_scraping >= date('now', '-7 days')
                ''')
                recent_stats = cursor.fetchone()
                
                summary = {
                    'total_urls_configuradas': len(self.category_urls),
                    'urls_categorias': self.category_urls,
                    'total_produtos_processados': total_processed,
                    'produtos_por_categoria': categories,
                    'ultimos_7_dias': {
                        'total_produtos_encontrados': recent_stats[0] or 0,
                        'novos_produtos': recent_stats[1] or 0,
                        'tempo_medio_execucao': recent_stats[2] or 0
                    },
                    'status': 'ativo',
                    'data_consulta': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                return summary
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resumo: {e}")
            return {'status': 'erro', 'mensagem': str(e)}
    
    def auto_discover_categories(self, force_refresh: bool = False) -> Dict[str, Any]:
        """
        Descobre automaticamente todas as categorias dispon√≠veis
        
        Args:
            force_refresh: Se deve for√ßar nova descoberta mesmo com cache
            
        Returns:
            Resultado da descoberta
        """
        logger.info("üîç Iniciando descoberta autom√°tica de categorias...")
        
        # Se j√° tem categorias descobertas e n√£o √© para for√ßar, usar cache
        if self.discovered_categories and not force_refresh:
            logger.info(f"üìã Usando cache: {len(self.discovered_categories)} categorias descobertas")
            return {
                'status': 'cache',
                'categories': self.discovered_categories,
                'total_discovered': len(self.discovered_categories)
            }
        
        try:
            # Descobrir categorias
            discovery_result = self.category_discovery.discover_all_categories()
            
            if discovery_result['status'] == 'success':
                self.discovered_categories = discovery_result['categories']
                
                # Salvar no banco para persist√™ncia
                self._save_discovered_categories(self.discovered_categories)
                
                logger.info(f"‚úÖ Descoberta conclu√≠da: {len(self.discovered_categories)} categorias encontradas")
                
                return {
                    'status': 'success',
                    'categories': self.discovered_categories,
                    'total_discovered': len(self.discovered_categories),
                    'execution_time': discovery_result.get('execution_time', 0)
                }
            else:
                logger.error(f"‚ùå Erro na descoberta: {discovery_result.get('message', 'Erro desconhecido')}")
                return discovery_result
                
        except Exception as e:
            logger.error(f"‚ùå Erro na descoberta autom√°tica: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'categories': []
            }
    
    def update_category_urls_from_discovery(self, categories: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Atualiza lista de URLs com categorias descobertas
        
        Args:
            categories: Lista de categorias (ou usar descobertas em cache)
            
        Returns:
            Resultado da atualiza√ß√£o
        """
        if not categories:
            categories = self.discovered_categories
        
        if not categories:
            logger.warning("‚ö†Ô∏è Nenhuma categoria descoberta para atualizar URLs")
            return {
                'status': 'warning',
                'message': 'Nenhuma categoria descoberta. Execute auto_discover_categories() primeiro.'
            }
        
        try:
            old_count = len(self.category_urls)
            new_urls = []
            
            # Adicionar URLs das categorias descobertas
            for category in categories:
                url = category.get('url')
                if url and url not in self.category_urls:
                    self.category_urls.append(url)
                    new_urls.append(url)
            
            new_count = len(self.category_urls)
            added_count = len(new_urls)
            
            logger.info(f"üìã URLs atualizadas: {old_count} ‚Üí {new_count} ({added_count} novas)")
            
            return {
                'status': 'success',
                'old_count': old_count,
                'new_count': new_count,
                'added_count': added_count,
                'new_urls': new_urls
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao atualizar URLs: {e}")
            return {
                'status': 'error',
                'message': str(e)
            }
    
    def validate_all_category_urls(self) -> Dict[str, Any]:
        """
        Valida todas as URLs de categorias (configuradas + descobertas)
        
        Returns:
            Resultado da valida√ß√£o
        """
        logger.info("üîç Validando todas as URLs de categorias...")
        
        all_urls = list(set(self.category_urls))  # Remove duplicatas
        
        valid_urls = []
        invalid_urls = []
        
        for url in all_urls:
            try:
                import requests
                response = requests.head(url, timeout=10)
                if response.status_code < 400:
                    valid_urls.append(url)
                    logger.debug(f"‚úÖ URL v√°lida: {url}")
                else:
                    invalid_urls.append({'url': url, 'status_code': response.status_code})
                    logger.warning(f"‚ö†Ô∏è URL inv√°lida ({response.status_code}): {url}")
            except Exception as e:
                invalid_urls.append({'url': url, 'error': str(e)})
                logger.warning(f"‚ùå Erro ao validar {url}: {e}")
        
        # Atualizar lista apenas com URLs v√°lidas
        self.category_urls = valid_urls
        
        result = {
            'status': 'success',
            'total_checked': len(all_urls),
            'valid_urls': len(valid_urls),
            'invalid_urls': len(invalid_urls),
            'valid_list': valid_urls,
            'invalid_list': invalid_urls
        }
        
        logger.info(f"‚úÖ Valida√ß√£o conclu√≠da: {len(valid_urls)}/{len(all_urls)} URLs v√°lidas")
        
        return result
    
    def _save_discovered_categories(self, categories: List[Dict[str, Any]]):
        """Salva categorias descobertas no banco para cache"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Criar tabela se n√£o existir
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS discovered_categories (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL,
                        url TEXT NOT NULL UNIQUE,
                        source TEXT,
                        has_products BOOLEAN,
                        status TEXT,
                        discovery_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Limpar registros antigos
                cursor.execute('DELETE FROM discovered_categories')
                
                # Inserir novas categorias
                for category in categories:
                    cursor.execute('''
                        INSERT INTO discovered_categories 
                        (name, url, source, has_products, status)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (
                        category.get('name', ''),
                        category.get('url', ''),
                        category.get('source', ''),
                        category.get('has_products', False),
                        category.get('status', '')
                    ))
                
                conn.commit()
                logger.debug(f"üíæ {len(categories)} categorias salvas no cache")
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar categorias descobertas: {e}")
    
    def close(self):
        """Fecha conex√µes"""
        if hasattr(self, 'category_discovery'):
            self.category_discovery.close() 
 
 
 
 